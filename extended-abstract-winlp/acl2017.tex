\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2017}
\usepackage{times}
\usepackage{latexsym}
\usepackage[english]{babel}
\usepackage{blindtext}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Who's to say what's funny? A computer using Language Models and Deep Learning, that's who!}

\author{Xinru Yan \& Ted Pedersen\\
  Department of Computer Science \\ University of Minnesota Duluth \\ Duluth, MN, 55812 USA \\
  {\tt \{yanxx418,tpederse\}@d.umn.edu}}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Humor is a defining characteristic of human beings. 
Our goal is to develop methods that automatically 
detect humorous statements and rank them on a 
continuous scale. In this paper we report on  results 
using a Language Model approach, and outline our
plans for using methods from Deep Learning.
\end{abstract}

\section{Introduction}
\textit{Computational humor} is an emerging area of 
research that ties together ideas from psychology, 
linguistics, and cognitive science. 
\textit{Humor generation} is the problem of automatically
creating humorous statements 
(e.g., \cite{StockS03}, \cite{ozbal2012computational})
while \textit{humor detection} is concerned with identifying
humor in text, and is sometimes treated as 
a binary classification problem where the goal is to
decide if some input is humorous or not 
(e.g., \cite{Learning:To:Laugh}, 
\cite{Recognizing:Humor:On:Twitter}, \cite{ShahafHM15},
\cite{MillerG15}). However, our interest is more in 
the continuous and subjective nature of humor. 

In order to account for the subjective nature of humor,
we learn a sense of humor from a dataset of tweets geared
towards a particular style of humor \cite{2016hashtagwars}. 
This data consists of humorous tweets which have been
submitted in response to hashtags given during the Comedy
Central TV show \textit{@midnight with Chris Hardwick}.
To represent the continuous aspect of humor (where not all
funny jokes are equally amusing), we focus on using Language
Models and methods from Deep Learning that allow for the
ranking of potentially humorous statements relative to 
each other. 

\section{Language Models}

We start with traditional Ngram language models for two reasons: 
\begin{enumerate}
\item Ngram language models can be customized to a particular kind of 
humor by using examples of that as the training data for the model, and
\item Ngram language models provide a probability value for each
input they are given, thus making it possible to rank statements
relative to each other.  
\end{enumerate}

We began this research by participating in SemEval-2017 Task 6 
\#HashtagWars: Learning a Sense of Humor \cite{PotashRR17}. This included
two subtasks : Pairwise Comparison (Subtask A) and Semi-ranking 
(Subtask B). Pairwise comparison asks a system to choose the funnier of
two tweets, while semi-ranking requires that 10 tweets be placed in
three categories (most funny, funny, less funny). 

%% submission should be anonymous, so anything that gives us away should
% be kept out til the final version

%%The Duluth system
%%\footnote{https://xinru1414.github.io/HumorDetection-SemEval2017-Task6/} 
Our system
estimated tweet probabilities using Ngram language models.
%% \cite{XT}. 
We created models
from two different data sets - a collection of funny tweets from the @midnight
program, and a corpus of news data that is freely available for 
research\footnote{http://www.statmt.org/wmt11/featured-translation-task.html}. 
We scored tweets using each model. Tweets that have a higher probability 
when using the funny tweet model were considered funnier. However, tweets 
that have a lower probability according to the news language model 
are viewed as being funnier since they are least like the (unfunny) news corpus.
We took a fairly standard approach to language modeling and used bigrams 
and trigrams as features in the model. We used KenLM \cite{Heafield-estimate} as our 
language modeling too, and used modified Kneser-Ney smoothing and back-off techniques. 
More details about our system refers to

Table 1 shows our results for both data sets when trained on 
bigrams and trigrams. The accuracy and the distance measures
are defined by the task organizers \cite{PotashRR17}. We seek 
high accuracy in picking the funnier tweet (subtask A) and low
distance (from the gold standard) in organizing the tweets into 
categories (subtask B). 

\begin{table}[h]
\begin{center}
\begin{tabular}{ |p{1.2cm}|p{1.2cm}|p{1.7cm}|p{1.7cm}|}
\hline
DataSet & N-gram & Subtask A Accuracy & Subtask B Distance \\
\hline
tweets & trigram & 0.397 & 0.967 \\
\hline
tweets & bigram & 0.406 & 0.944 \\
\hline
news & trigram & 0.627 & 0.872 \\
\hline
news & bigram & 0.624 & 0.853 \\
\hline
\end{tabular}
\caption{Experimental results}
\end{center}
\end{table}

These results show that the trigram model trained on the news data
has a significant advantage over the tweets data. Bigram language
models performed slightly better than trigram models on both data
sets. In the official evaluation of SemEval-2017 Task 6 our most
effective method was trigram language models trained on the news
data - this placed fourth in Subtask A and first in Subtask B.  

We believe that the significant advantage of the news data over 
the tweet data is caused by the difference in quantity between 
corpora. The tweet data only consisted of approximately 21,000 tweets,
whereas the news data totals approximately 6.2 GB of text.
In the future we intend to collect more tweet data, especially those 
participating in the ongoing \#HashtagWars staged nightly by @midnight. 
We also plan to experiment with equal amounts of tweet data and
news data, to see if one has an inherent advantage over the other.

Finally, our language models performed better on subtask A, the pairwise
comparison, suggesting that the ranking problem is more demanding
and will require further development. To that end we are considering the
use of neural network and Deep Learning approaches, which we will 
discuss in the following section.

\section{Deep Learning}

Our system performed well in the SemEval task, confirming the ability 
of language models to detect humor with focusing on its continuous 
and subjective nature. Going forward, language models certainly 
can characterize humor in a more comprehensive way with more 
complex implementations.

Recently, studies have shown that Recurrent Neural Networks 
(RNN) such as LSTM neural networks are exceptionally powerful 
in language modeling based on its ability to take into account 
of all preceding words over a word sequence \cite{LSTM1} 
\cite{LSTM2}. Also, in their work of learning a sense of humor, 
\cite{2016hashtagwars} points out that due to the high portion 
of out of vocabulary (OOV) words generated by puns in the 
humorous tweet data, character-level Constitutional Neural 
Networks (CNN) model would be more suitable for capturing the 
single-token puns comparing to token level models. In addition, 
\cite{CNN}'s study proves that character-level neural language 
models outperform state-of-art word-level neural language 
models. Moving forward, considering the promising future of 
neural networks, we would like to build a character-level neural 
language model (NLM) which relies on both LSTM RNN and character-level 
CNN to improve our current system performance.

Last but not the least, \cite{2016hashtagwars} states that 
external knowledge is crucial in order to detecting humor from 
the tweet dataset based on its nature. In the future we intend 
to make use of external knowledge in the NLM in possibly two 
ways: With a deeper understanding of what kinds of external 
knowledge are the most useful such as movie and book titles, 
celebrity and song names, one is to incorporate them as features 
in the NLM; The other is to combine the NLM with a Neural 
Turing Machine (NTM) \cite{graves2014neural}, which is particularly 
designed for interacting with external interfaces, with a 
profound and solid study of NTM.

\section{Conclusion}

Humor has not been addressed broadly in current computational 
research area. Our research focuses on humor detection, developing 
systems that can capture its continuous and subjective nature. 
 
% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliography{acl2017}
\bibliography{acl2017}
\bibliographystyle{acl_natbib}

\end{document}
