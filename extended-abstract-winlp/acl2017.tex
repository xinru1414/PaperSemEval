%
% File acl2017.tex
%
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2017}
\usepackage{times}
\usepackage{latexsym}
\usepackage[english]{babel}
\usepackage{blindtext}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Extended Abstract for WiNLP}

\author{Xinru Yan \& Ted Pedersen\\
  Department of Computer Science \\ University of Minnesota Duluth \\ Duluth, MN, 55812 USA \\
  {\tt \{yanxx418,tpederse\}@d.umn.edu}}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Humor represents one of the most unique and intelligent activities that define humans. Our research addresses humor detection task by using a variety of methods with the focus on the continuous and subjective nature of humor based on a particular humorous Twitter dataset, instead of treating it as a binary classification task. So far we have applied language model approach to this problem. This paper presents the current work of our research along with promising results, as well as possible future work.
\end{abstract}

\section{Introduction}
Humor is considered to be a human-only trait and one of the most amusing and mystifying human activities. It enters the domain of philosophy, sociology, psychology, linguistics and computer science. With the increasing development of Artificial Intelligence(AI), Machine Learning(ML) and computational linguistics, \textit{Computational humor} has found its way to numerous studies. Humor generation and humor detection have been the prevailing focus of computational humor. Researchers have developed well working systems to produce humor (e.g., \cite{StockS03}, \cite{ozbal2012computational}). However, \textit{humor detection} remains a less explored and challenging problem. 

Most studies have treated humor detection as a binary classification problem, which is to classify whether a piece of data is humorous (e.g., \cite{Learning:To:Laugh}, \cite{Recognizing:Humor:On:Twitter}, \cite{ShahafHM15}, \cite{MillerG15}). Although the binary classification technique is an applicable approach, it ignores the continuous and subjective nature of humor. 

In our research, we specifically take these factors into account when we choose methods and develop systems to detect humor. In order to address the subjective characteristic of humor, we focus on learning a sense of humor from a particular tweet dataset constructed by Potash et al \cite{2016hashtagwars}, which consists of humorous tweets submitted to a comedy show \textit{@midnight}. To represent the continuous trait of humor, we use methods that rank tweets based on their humorous level rather than classifying whether each tweet is humorous.   
 
\section{Language Models}
We chose traditional N-gram Language Models (LMs) as a starting point of our research for two reasons: First, training N-gram LMs allows us to detect humor by learning a sense of humor from a word and its neighbors in a tweet. Additionally, language model approach is suitable to represent the continuous nature of humor considering its ability of ranking tweets based on the probability score it computes for each tweet. Our research is associated with the SemEval-2017 Task 6 \#HashtagWars: Learning a Sense of Humor \cite{PotashRR17} since its purpose corresponds to ours. There are two subtasks involved: Pairwise Comparison (Subtask A) and Semi-ranking (Subtask B). More details about the task refers to \cite{PotashRR17}. 

In the SemEval task, we developed system Duluth \footnote{https://xinru1414.github.io/HumorDetection-SemEval2017-Task6/} to estimate tweet probability using N-gram LMs. Our system ranked tweets based on how funny they are by training N-gram LMs on two different datasets: the funny tweet data provided by the task and the news data which is freely available for research \footnote{http://www.statmt.org/wmt11/featured-translation-task.html}. Tweets that have a higher probability according to the tweet data language model are ranked as being funnier. However, tweets that are less probable according to the news language model are considered the funnier since they are the least like the (unfunny) news corpus. We relied on both bigrams and trigrams when training our models considering tweets' concise and short nature. KenLM \cite{Heafield-estimate} was used as our language modeling tool, with modified Kneser-Ney smoothing and back-off technique. More details about our system refers to \cite{XT}.

Table 1 shows our results based on LMs trained on both datasets using bigram and trigram. Note that the accuracy and the distance measurements listed are defined by the task organizers \cite{PotashRR17}. For Subtask A, higher accuracy score represents better system performance; for Subtask B, lower distance score means the system works more effective.

\begin{table}[h]
\begin{center}
\begin{tabular}{ |p{1.2cm}|p{1.2cm}|p{1.7cm}|p{1.7cm}|}
\hline
DataSet & N-gram & Subtask A Accuracy & Subtask B Distance \\
\hline
tweets & trigram & 0.397 & 0.967 \\
\hline
tweets & bigram & 0.406 & 0.944 \\
\hline
news & trigram & 0.627 & 0.872 \\
\hline
news & bigram & 0.624 & 0.853 \\
\hline
\end{tabular}
\caption{Results based on bigram and trigram LMs on both datasets. The trigram LM trained on the news data ranked 4th place on Subtask A and 1st place on Subtask B during the SemEval task evaluation.}
\end{center}
\end{table}

From the results we can tell that: LMs trained on the news data had a significant advantage over models trained on the tweets data; Bigram LMs performed slightly better than trigram LMs on both datasets; Our system had a better performance on Subtask A over B.

We believe that the significant advantage of the news data over the tweet data is caused by the difference in quantity between corpora. The tweet data was significantly smaller than the news data. In the future we intend to collect more tweet data, especially the ones participating the \#HashtagWars. We also plan to experiment on cutting the amount of news data and then build the models to see how the results compare.

Our system performed much better on Subtask A comparing to B, which reveals that the semi-ranking task has a higher requirement on the system to represent the continuous nature of humor comparing to the pair-wise comparison.

\section{Deep Learning}
Our system performed well in the SemEval task, confirming the ability of language models to detect humor with focusing on its continuous and subjective nature. Going forward, language models certainly can characterize humor in a more comprehensive way with more complex implementations.

Recently, studies have shown that Recurrent Neural Networks (RNN) such as LSTM neural networks are exceptionally powerful in language modeling based on its ability to take into account of all preceding words over a word sequence \cite{LSTM1} \cite{LSTM2}. Also, in their work of learning a sense of humor, \cite{2016hashtagwars} points out that due to the high portion of out of vocabulary (OOV) words generated by puns in the humorous tweet data, character-level Constitutional Neural Networks (CNN) model would be more suitable for capturing the single-token puns comparing to token level models. In addition, \cite{CNN}'s study proves that character-level neural language models outperform state-of-art word-level neural language models. Moving forward, considering the promising future of neural networks, we would like to build a character-level neural language model (NLM) which relies on both LSTM RNN and character-level CNN to improve our current system performance.

Last but not the least, \cite{2016hashtagwars} states that external knowledge is crucial in order to detecting humor from the tweet dataset based on its nature. In the future we intend to make use of external knowledge in the NLM in possibly two ways: With a deeper understanding of what kinds of external knowledge are the most useful such as movie and book titles, celebrity and song names, one is to incorporate them as features in the NLM; The other is to combine the NLM with a Neural Turing Machine (NTM) \cite{graves2014neural}, which is particularly designed for interacting with external interfaces, with a profound and solid study of NTM.

\section{Conclusion}
Humor has not been addressed broadly in current computational research area. Our research focuses on humor detection, developing systems that can capture its continuous and subjective nature. 
 
% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliography{acl2017}
\bibliography{acl2017}
\bibliographystyle{acl_natbib}

\end{document}
