%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% a0poster Portrait Poster
% LaTeX Template
% Version 1.0 (22/06/13)
%
% The a0poster class was created by:
% Gerlinde Kettl and Matthias Weiser (tex@kettl.de)
% 
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a0,portrait]{a0poster}

\usepackage{multicol} % This is so we can have multiple columns of text side-by-side
\columnsep=100pt % This is the amount of white space between the columns in the poster
\columnseprule=3pt % This is the thickness of the black line between the columns in the poster

\usepackage[svgnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors

\usepackage{times} % Use the times font
%\usepackage{palatino} % Uncomment to use the Palatino font

\usepackage{graphicx} % Required for including images
\graphicspath{{figures/}} % Location of the graphics files
\usepackage{booktabs} % Top and bottom rules for table
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures
\usepackage{amsfonts, amsmath, amsthm, amssymb} % For math fonts, symbols and environments
\usepackage{wrapfig} % Allows wrapping text around tables and figures

\begin{document}

%----------------------------------------------------------------------------------------
%	POSTER HEADER 
%----------------------------------------------------------------------------------------

% The header is divided into two boxes:
% The first is 75% wide and houses the title, subtitle, names, university/organization and contact information
% The second is 25% wide and houses a logo for your university/organization or a photo of you
% The widths of these boxes can be easily edited to accommodate your content as you see fit

\begin{minipage}[b]{0.75\linewidth}
\VeryHuge \color{NavyBlue} \textbf{\#HashtagWars: Learning a Sense of Humor} \color{Black}\\ % Title
\huge\textit{Language Models in Humor Detection}\\[2cm] % Subtitle
\huge \textbf{Xinru Yan \& Ted Pedersen}\\[0.5cm] % Author(s)
\huge Department of Computer Science University of Minnesota Duluth\\[0.4cm] % University/organization
\Large \texttt{\{yanxx418 \& tpederse\} @d.umn.edu}\\
\end{minipage}
%
\begin{minipage}[b]{0.25\linewidth}
\includegraphics[width=22cm]{logo.png}\\
\end{minipage}

\vspace{1cm} % A bit of extra whitespace between the header and poster content

%----------------------------------------------------------------------------------------

\begin{multicols}{2} % This is how many columns your poster will be broken into, a portrait poster is generally split into 2 columns

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

%\color{Navy} % Navy color for the abstract

%\begin{abstract}
 
%\end{abstract}

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\color{SaddleBrown} % SaddleBrown color for the introduction

\section*{\LARGE Introduction}
This research is associated with the SemEval-2017 Task6 \#HashtagWars: Learning a Sense of Humor. The task aims to characterize the sense of humor of a particular source, which consists of humorous tweets submitted to a comedy show \textit{@midnight}. Two subtasks are involved: 
\begin{itemize}
\item Subtask A: Pairwise Comparison -- a system should predict which tweet is funnier for every possible combination of tweet pairs from a given hashtag file.
\item Subtask B: Semi-Ranking -- a system should produce a ranking of tweets from funniest to least funny given an input file of tweets for a specific hashtag file. 
\end{itemize}
We developed a system called Duluth that participated in the task. The system completed Task A and Task B using ngram language models (LMs), ranking well during evaluation.

%----------------------------------------------------------------------------------------
%	BACKGROUND
%----------------------------------------------------------------------------------------

\color{DarkSlateGray} % DarkSlateGray color for the rest of the content

\section*{\LARGE Background}
\begin{enumerate}
\item N-gram models: predict the upcoming word from the previous N-1 words. An N-gram is a contiguous sequence of N words. For example, in tweet ``tears in Ramen \#SingleLifeIn3Words'', ``tears'' is an unigram; ``tears in'' is a bigram and ``tears in Ramen'' is a trigram.
\item Markov assumption: the probability of a word depends only on a small number of previous words. For trigram LM, we have:
\begin{equation}
P(w_n|w_1^{n-1})\approx P(w_n|w_{n-2}, w_{n-1})
\end{equation}
\item Trigram LM: using trigrams to computer the probability of a complete sequence of words. General equation:
\begin{equation}
P(w_1^n)\approx \prod_{k=1}^{n} P(w_k|w_{k-2}, w_{k-1})
\end{equation}
\item How funny the tweet is comparing to the ``common language'': in the study on how phrasing affects memorability, in favor of evaluating how memorable a movie quote is, researchers evaluate its likelihood with the respect of the LMs trained on news data \cite{hello}. Movie quotes that are less like the ``common language'' are more memorable. The idea of using LMs to assess the memorability of a quote is suitable for our purpose of detecting how humorous a tweet is. 
\end{enumerate}

%----------------------------------------------------------------------------------------
%	DATASET
%----------------------------------------------------------------------------------------
\color{Navy}

\section*{\LARGE Dataset}
Our system estimates tweet probability using ngram LMs. Except for using tweets provided by the task to train ngram LMs, our system also trained ngram LMs on English news data in order to evaluate how funny a tweet is. Tweets that were more like the tweets model, or less like the news model, were ranked as being more funny.

\begin{itemize}
\item The tweets data -- provided by the SemEval task ; consists of 106 hashtag files, about 21,580 tokens.\\\\
\begin{tabular}{ c | c } 
\toprule
\multicolumn{2}{c}{The hashtag:	\#SingleLifeIn3Words} \\
\hline
tweet & tweet\_label\\ 
\hline
tears in Ramen \#SingleLifeIn3Words @midnight & 2 \\ 
\hline
Ben and Jerry's \#SingleLifeIn3Words @midnight & 1 \\
\hline
Pet is kid. @midnight \#SingleLifeIn3Words & 0 \\
\bottomrule
\end{tabular}
\\\\
\item The news data -- We collected in total of 6.2 GB of English news data, about 2,002,655 tokens, from the News Commentary Corpus and the News Crawl Corpus (2008, 2010 and 2011) \footnote{http://www.statmt.org/wmt11/translation-task.html\#download}.
\end{itemize}





%----------------------------------------------------------------------------------------
%	METHODS
%----------------------------------------------------------------------------------------
\color{DarkSlateGray} % DarkSlateGray color for the rest of the content
\section*{\LARGE Method}
Our system solves the given two subtasks in four steps:
\begin{enumerate}
\item Corpus preparing and pre-processing: Collect training data files to form one corpus. Pre-processing includes filtering and tokenization.
\item Language model training: Build ngram LMs by feeding the corpus to KenLM Language Model Toolkit \cite{Heafield-estimate}. 
\item Tweet scoring: Get log probability for each tweet based on the trained ngram language model.
\item Tweet prediction: According to the log probability
\begin{itemize}
\item Subtask A -- Given two tweets, comparing them and predicting which one is funnier. 
\item Subtask B -- Given a set of tweets associated with one hashtag, ranking tweets from the funnest to the least funny.
\end{itemize}
\end{enumerate}

%----------------------------------------------------------------------------------------
%	RESULTS 
%----------------------------------------------------------------------------------------
\color{Navy}

\section*{\LARGE Results}
Run \# 1 respresents trigram LM trained on the tweets data. Run \#2 represents trigram LM trained on the news data.\\\\
\begin{tabular}{l l l l | l l l l} 
\toprule
\multicolumn{4}{c}{Task A} & \multicolumn{4}{|c}{Task B}\\
\hline
\textbf{Rank} & \textbf{Name} & \textbf{Run} & \textbf{Accuracy} & \textbf{Rank} & \textbf{Name} & \textbf{Run} & \textbf{Distance}\\
\hline
1 & djd1283 & 2 & 0.675 & \color{Green} 1 & \color{Green} Xinru	& \color{Green} 2	& \color{Green} 0.872\\
2 & djd1283 & 1 & 0.637 & 2	& sylar	& 1	& 0.908\\
3 & cbaziotis & 1 & 0.632 & 3	& xiwu & 1 & 0.924\\
\color{Green} 4 & \color{Green} Xinru & \color{Green} 2 & \color{Green} 0.627 & 4 & xiwu	& 2 & 0.924\\
5 & acattle & 1 & 0.523 & 5	& Rutal & 2 & 0.938\\
6 & Rutal & 1 & 0.506 & 6 & sylar & 2 & 0.944\\
7 & sylar & 1 & 0.403 & 7 & Rutal & 1 & 0.949\\
\color{Green} 8 & \color{Green} Xinru & \color{Green} 1 & \color{Green} 0.397 & \color{Green}8 & \color{Green} Xinru & \color{Green} 1 & \color{Green} 0.967\\
9 & sylar & 2 & 0.359 & 9 & AlexandraFlescan & 1 & 1.0\\
10 & xiwu & 1 & 0.187 & NA & NA & NA & NA\\
\bottomrule
\end{tabular}
\captionof{table}{SemEval 2017 Task 6 Evaluation Results}

%----------------------------------------------------------------------------------------
%	DISCUSSION
%----------------------------------------------------------------------------------------

\color{SaddleBrown} % SaddleBrown color for the conclusions to make them stand out

\section*{\LARGE Discussion}

\begin{itemize}
\item Lack of tweets data could cause the failure on the tweets LMs. We would like to train news LMs using about as much text as we have for the tweets and see how the results compare.
\item To improve the current system : collect more tweets that participate in the hashtag wars for tweets LMs and more news data for news LMs. 
\item Try machine learning techniques.
\end{itemize}



%----------------------------------------------------------------------------------------
%	REFERENCES
%----------------------------------------------------------------------------------------

\nocite{*} % Print all references regardless of whether they were cited in the poster or not
\bibliographystyle{plain} % Plain referencing style
\small \bibliography{sample} % Use the example bibliography file sample.bib

%----------------------------------------------------------------------------------------
%	ACKNOWLEDGEMENTS
%----------------------------------------------------------------------------------------

%\section*{Acknowledgements}


%----------------------------------------------------------------------------------------

\end{multicols}
\end{document}